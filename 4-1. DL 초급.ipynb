{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-1. DL 초급","private_outputs":true,"provenance":[{"file_id":"1RPdTdBDVOOGymKbhnOeHy-xKgeZl3gV-","timestamp":1605683162830}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8IFct0yedsTy"},"source":["\n","# Reference\n","[Tensorflow: 사전 제작된 에스티메이터](https://www.tensorflow.org/tutorials/estimator/premade?hl=ko)"]},{"cell_type":"markdown","metadata":{"id":"jtQUcZT-LH-B"},"source":["# Workflow\n","1. EDA\n","2. Dataset과 feature columns을 통한 입력함수 생성\n","3. Estimator 활용\n"]},{"cell_type":"markdown","metadata":{"id":"c5w4m5gncnGh"},"source":["# 1. EDA\n","\n","데이터: Iris(붓꽃) data\n","Iris를 구성하는 꽃받침과 꽃잎의 크기에 따라서 Iris를 세 가지의 다른 종으로 분류되어 있는 데이터.\n","\n","1개의 데이터 행은 다음과 같이 구성되어 있음\n","- 꽃받침 길이\n","- 꽃받침 넓이\n","- 꽃잎 길이\n","- 꽃잎 너비\n","- 종\n","\n"]},{"cell_type":"code","metadata":{"id":"jPo5bQwndr9P"},"source":["import tensorflow as tf\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PumyCN8VdGGc"},"source":["train_path = tf.keras.utils.get_file(\n","    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n","test_path = tf.keras.utils.get_file(\n","    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n","\n","CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n","SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n","\n","train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n","test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOJt-ML4hAwI"},"source":["train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Xoz08OULH-B"},"source":["꽃의 종에 따라서 꽃잎과 꽃받침의 길이에 차이가 있음을 확인"]},{"cell_type":"code","metadata":{"id":"7pyzRcM1LH-B"},"source":["val_by_spec = train.groupby(\"Species\").mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UuPT5A3LH-B"},"source":["val_by_spec.plot(kind='bar')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jQJEYfVvfznP"},"source":["데이터를 Input과 Output으로 분리"]},{"cell_type":"code","metadata":{"id":"zM0wz2TueuA6"},"source":["train_y = train.pop('Species')\n","test_y = test.pop('Species')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2OcguDfBcmmg"},"source":["# 2. 입력함수\n"]},{"cell_type":"markdown","metadata":{"id":"qmEADswiwEpB"},"source":["### tf.data.Dataset\n","입력함수는 `tf.data.Dataset`를 이용하여 만들 수 있음. `tf.data.Dataset`은 다양한 데이터를 다룰 수 있으며, 배치기능 등을 포함하고 있음.\n","\n","`tf.data.Dataset`을 통해 모델 학습에서 입력 파이프라인을 빌드할 수 있음"]},{"cell_type":"code","metadata":{"id":"T20u1anCi8NP"},"source":["def input_fn(features, labels, training=True, batch_size=256):\n","    # Pandas 타입의 데이터를 tf.data.Dataset 타입으로 변환\n","    # features의 경우 feature_column을 이용하여 dictionary를 통해 상세화 할 수 있음\n","    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n","\n","    if training:\n","        dataset = dataset.shuffle(1000).repeat()\n","        \n","    # 배치크기에 맞는 데이터를 반환한다\n","    return dataset.batch(batch_size)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxhtRWT6LH-C"},"source":["input_fn(train.head(), train_y.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRXuPlH3LH-C"},"source":["feature에 `dict` 가 없는 경우에는 다음과 같이 입력된 feature의 column을 인식하지 못함"]},{"cell_type":"code","metadata":{"id":"cwgLZp55LH-C"},"source":["def input_fn2(features, labels, training=True, batch_size=256):\n","    # Pandas 타입의 데이터를 tf.data.Dataset 타입으로 변환\n","    # features의 경우 feature_column을 이용하여 dictionary를 통해 상세화 할 수 있음\n","    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n","\n","    if training:\n","        dataset = dataset.shuffle(1000).repeat()\n","        \n","    # 배치크기에 맞는 데이터를 반환한다\n","    return dataset.batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDTUnL4GLH-C"},"source":["input_fn2(train.head(), train_y.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYrgkXx_LH-C"},"source":["### Feature columns 을 이용한 feature 정의. \n","\n","Iris data는 모두 Numerical data라서 `tf.feature_column.numeric_column`를 사용함. Categorical data도 feature column 으로 정의할 수 있다."]},{"cell_type":"code","metadata":{"id":"ZTTriO8FlSML"},"source":["my_feature_columns = []\n","for key in train.keys():\n","    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbW-jZ_qLH-C"},"source":["my_feature_columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jpKkhMoZljco"},"source":["Feature columns can be far more sophisticated than those we're showing here.  You can read more about Feature Columns in [this guide](https://www.tensorflow.org/guide/feature_columns).\n","\n","Now that you have the description of how you want the model to represent the raw\n","features, you can build the estimator."]},{"cell_type":"markdown","metadata":{"id":"kuE59XHEl22K"},"source":["# 3. estimator\n","\n","tensorflow에서는 직접 구성한 네트워크 외에도 시전에 정의된 네트워크를 사용할 수 있다.\n","\n","scikit-learn에서 제공하는 `estimator`와 같이 간편하게 사용할 수 있다.\n","\n","\n","* `tf.estimator.DNNClassifier` for deep models that perform multi-class\n","  classification.\n","* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.\n","* `tf.estimator.LinearClassifier` for classifiers based on linear models.\n","\n"]},{"cell_type":"code","metadata":{"id":"qnf4o2V5lcPn"},"source":["# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n","classifier = tf.estimator.DNNClassifier(\n","    feature_columns=my_feature_columns,\n","    # Two hidden layers of 30 and 10 nodes respectively.\n","    hidden_units=[30, 10],\n","    # The model must choose between 3 classes.\n","    n_classes=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzzt5nUpmEe3"},"source":["# 4. 학습, 평가, 예측\n","\n","Now that you have an Estimator object, you can call methods to do the following:\n","\n","* Train the model.\n","* Evaluate the trained model.\n","* Use the trained model to make predictions."]},{"cell_type":"markdown","metadata":{"id":"rnihuLdWmE75"},"source":["### 모델 학습\n","Train the model by calling the Estimator's `train` method as follows:"]},{"cell_type":"code","metadata":{"id":"4jW08YtPl1iS"},"source":["# Train the Model.\n","classifier.train(\n","    input_fn=lambda: input_fn(train, train_y, training=True),\n","    steps=5000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ybiTFDmlmes8"},"source":["Note that you wrap up your `input_fn` call in a\n","[`lambda`](https://docs.python.org/3/tutorial/controlflow.html)\n","to capture the arguments while providing an input function that takes no\n","arguments, as expected by the Estimator. The `steps` argument tells the method\n","to stop training after a number of training steps.\n"]},{"cell_type":"markdown","metadata":{"id":"HNvJLH8hmsdf"},"source":["### 모델 평가\n","Now that the model has been trained, you can get some statistics on its\n","performance. The following code block evaluates the accuracy of the trained\n","model on the test data:\n"]},{"cell_type":"code","metadata":{"id":"A169XuO4mKxF"},"source":["eval_result = classifier.evaluate(\n","    input_fn=lambda: input_fn(test, test_y, training=False))\n","\n","print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnPMP5EHph17"},"source":["Unlike the call to the `train` method, you did not pass the `steps`\n","argument to evaluate. The `input_fn` for eval only yields a single\n","[epoch](https://developers.google.com/machine-learning/glossary/#epoch) of data.\n","\n","\n","The `eval_result` dictionary also contains the `average_loss` (mean loss per sample), the `loss` (mean loss per mini-batch) and the value of the estimator's `global_step` (the number of training iterations it underwent).\n"]},{"cell_type":"markdown","metadata":{"id":"ur624ibpp52X"},"source":["### 신규 데이터 예측\n","You now have a trained model that produces good evaluation results.\n","You can now use the trained model to predict the species of an Iris flower\n","based on some unlabeled measurements. As with training and evaluation, you make\n","predictions using a single function call:"]},{"cell_type":"code","metadata":{"id":"wltc0jpgng38"},"source":["# Generate predictions from the model\n","expected = ['Setosa', 'Versicolor', 'Virginica']\n","predict_x = {\n","    'SepalLength': [5.1, 5.9, 6.9],\n","    'SepalWidth': [3.3, 3.0, 3.1],\n","    'PetalLength': [1.7, 4.2, 5.4],\n","    'PetalWidth': [0.5, 1.5, 2.1],\n","}\n","\n","def input_fn(features, batch_size=256):\n","    \"\"\"An input function for prediction.\"\"\"\n","    # Convert the inputs to a Dataset without labels.\n","    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n","\n","predictions = classifier.predict(\n","    input_fn=lambda: input_fn(predict_x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JsETKQo0rHvi"},"source":["The `predict` method returns a Python iterable, yielding a dictionary of\n","prediction results for each example. The following code prints a few\n","predictions and their probabilities:"]},{"cell_type":"code","metadata":{"id":"Efm4mLzkrCxp"},"source":["for pred_dict, expec in zip(predictions, expected):\n","    class_id = pred_dict['class_ids'][0]\n","    probability = pred_dict['probabilities'][class_id]\n","\n","    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n","        SPECIES[class_id], 100 * probability, expec))"],"execution_count":null,"outputs":[]}]}